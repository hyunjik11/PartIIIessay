\documentclass{article}
\usepackage{nips06,times}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bm}
\usepackage[ruled,boxed]{algorithm2e}

\theoremstyle{plain}
%\documentstyle[nips06_09,times]{article}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem*{theorem*}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{def*}{Definition}

\title{Bayesian Approaches to Collaborative Filtering on Netflix Data}


\author{
Hyun Jik Kim \\
Department of Pure Mathematics and Mathematical Statistics\\
University of Cambridge\\
Mathematical Tripos Part III \\
\texttt{hjk42@cam.ac.uk} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\begin{document}

\maketitle

\begin{abstract}
Collaborative filtering defines a branch of techniques for tackling the following supervised learning problem: making predictions(filtering) about the preferences of a user, based on information regarding the preference of many users (collaborating).
Having obtained such predictions, it is then a simple task to build a recommender system for users; we simply recommend the items with highest preference by a given user.
In this paper, we first introduce the three most successful Bayesian algorithms for collaborative filtering on the Netflix dataset. These are \textbf{Probabilistic Matrix Factorization} (PMF), its variant \textbf{Bayesian PMF} (BayesPMF), and \textbf{Variational Bayes} (VB). We describe their mechanisms in full, fleshing out the missing details in the original papers. We then give results of authentic numerical experiments for direct comparison of their empirical performances and running time. Moreover we show results of experiments using combinations of these algorithms as an attempt to achieve better performance. Finally, we suggest further models and algorithms for the Netflix data which are worthy of interest. The hidden but perhaps most important purpose of this paper is to describe, explain, and provide diverse interpretations of various key ideas in Bayesian inference, including model construction with latent variables, extension to hierarchical models, MAP estimation, batch learning, Monte Carlo inference, Variational inference for models with latent variables and its relation to the EM algorithm. By presenting these ideas and inference methods in the context of collaborative filtering, the paper aims to provide helpful insight to the reader's understanding of Bayesian inference.
\end{abstract}

\section{Introduction}

Prediction of user ratings applies to various contexts, such as for online videos, books and other commercial products. In this paper, we will focus on movie ratings by users provided by the Netflix dataset, the largest publicly available movie rating data. This was publicised during the Netflix Prize in 2009, a competition organised by Netflix for the most accurate recommender system that predicts user ratings, given the user rating history [2 in VB]. Netflix provided just over 100,000,000 ratings from around 480,000 randomly chosen users and around 18,000 movies which they have rated, each with an integer between 1 and 5, collected between 1998 and 2005. The task is to predict a pre-specified set of 3 million unobserved ratings (test set) from these users over these movies. The metric for error is the root mean-squared error (RMSE) over the test set. We use Cinematch, Neflix's own system, with RMSE 0.9474 as a baseline.

Let us introduce some notation and terminology to begin with. Let there be $N$ users with $M$ movies. Each user $u_i$ rates movie $m_j$ with rating $R_{ij} \in \{1,...,K\}$. Hence the rating matrix $R$ is incomplete. In fact, it is incredibly sparse as most users will only have rated a small fraction of the total set of movies. Collaborative filtering aims to fill $R$ by only using the already filled entries (observed ratings) of $R$. The underlying assumption for this matrix completion that if user A has a similar rating as user B on a movie, then A is more likely to share B's rating on a different movie than another user selected at random. 

This approach is contrary to content-based filtering, which predicts user ratings based on attributes of movies such as genre,number of viewings,director,cast etc. There are several drawbacks of content-based filtering, such as limited content analysis and over-specialisation, but the main difficulty in applying content-based filtering to a dataset as large as the Netflix data is that it requires building user profiles; this highly memory intensive task is unsuitable for large data sets. Also it is not so clear as to how detailed the profiles should be made and how the weights should be given to different attributes of films. This is why the vast majority of approaches to the Netflix problem are based on collaborative filtering, which deals with a problem of reduced complexity, and thus can be seen as a step towards automation.

Collaborative filtering can further be classified into two approaches: memory-based and model-based. The former uses the rating data  to calculate similarities between users or between movies, and makes predictions based on these similar users\/movies, called neighbours. Then a certain function of the similarity and observed ratings is used to predict ratings. A popular example would be k-NN, where a weighted average of the k nearest neighbours' ratings on a movie is the prediction. The similarity measure used is normally not a metric as the triangle inequality does not hold (two users with preferences dissimilar to a third user may have similar preferences). This implies that we need a similarity measure between all pairs of users, the number of which is $O(N^2)$ hence giving rise to scalability issues for big data such as the Netflix dataset. Moreover the sparsity of the data implies that there could only be a handful of truely similar users, severely limiting the set of movies for which a sensible prediction can be made. A more fundamental problem is that there is no explicit statistical model, so very little insight in the data is gained when creating a memory-based prediction system. 

On the other hand, model-based collaborative filtering methods use the rating data to train a statistical model, which can then be used to make predictions. There have been various models in the literature even before the Netflix Prize, notably cluster based models ([5,6,7,8] of CL via Gaussian PLSA paper) and probabilistic models such as [Gaussian pLSA]. These algorithms seem to show impressive results on standard datasets such as MovieLens and EachMovie. However we must bear in mind that these datasets have had all users with fewer ratings than a lower threshold removed, which are intuitively the most difficult cases. The Netflix data, on the other hand, is very imbalanced: there coexist infrequent users with less than 5 ratings and frequent users with more than 10,000 ratings. Moreover the previously mentioned data sets are orders of magnitudes smaller than the Netflix data in size, and it has become apparent that scalability is also one of the main issues with these existing models.

The breakthrough for scalable model-based approaches was the clever idea of applying matrix factorisation to the rating matrix. We factorise the $N$ by $M$ rating matrix $R$ as a product of two matrices $U$ and $V^T$, where $U$ and $V$ are $N$ by $D$ and $M$ by $D$ respectively, where $D$ is a positive integer to be chosen. They are referred to as the user matrix and the movie matrix. Instead of learning $R$ directly, we build a model for $R$ in terms of $U$ and $V$, and try to learn $U$ and $V$ so that the error on the observed ratings is minimised. Then we simply fill in the blanks of R by multiplying out $U$ and $V^T$. The intuition behind this model is that there are only a few factors which affect the user's rating of a movie. So each row of $V$ can be interpreted as the $D$ features of a movie which affect the rating of users, and then each row of $U$ would correspond to the user's weights given to each feature. Note here that the choice of a suitable dimension $D$ is important. If $D$ is large, we will always be able to choose $U$ and $V$ such that we have perfect predictions on observed ratings, the training data. This hence leads to overfitting, as well as being computationally infeasible. So we want $D$ to be small, but not too small as then it might not capture all the different features responsible for a rating.

From a mathematical point of view, we note that if $R=UV^T$, then $rank(R)\leq D$. Hence finding $U$ and $V$ is equivalent to finding the best rank $D$ approximation to $R$ in the squared error sense. It is a standard result in linear algebra that this can easily be obtained from the Singular Value Decomposition (SVD) of $R$, commonly referred to as the Matrix Approximation Lemma [The approximation of one matrix by another of lower rank].

\begin{theorem*}[Singular Value Decomposition]
Suppose $R$ is a real $N \times M$ matrix. Then there exists a factorisation of the form
$R=U\Sigma V^T$ where $U$ and $V$ are $N \times N$ and $M \times M$ orthogonal matrices and $\Sigma$ is a $N \times M$ diagonal matrix with the diagonal entries in descending order.
\end{theorem*}

\begin{lemma*}[Matrix Approximation Lemma]
Let $U\Sigma V^T$ be the SVD of a real matrix $R$, with the diagonal entries of $\Sigma$ being $\sigma_1. \sigma_2, ... $. Then for $D\leq min(M,N) $, $\Sigma_D=diag(\sigma_1,...,\sigma_D)$, $U\Sigma_D V^T$ is the best rank $D$ approximation to $R$ in Frobenius norm.
\end{lemma*}

However, the problem with our rating matrix is that it is incomplete-some entries are missing. The above result holds for $R$ complete. This seemingly small modification results in a non-convex optimisation problem, and an approach different to standard SVD computation needs to be employed. Nonetheless there do exist SVD extensions which deal successfully with this problem, such as the use of the EM algorithm where the unobserved entries are modelled as latent variables [10 of VB], Gradient Boosting with successive rank 1 updates to U and V, and many other variants. These approaches have shown to be successful on the Netflix data. However, these procedures have also shown to overfit easily due to the extreme sparsity of the rating matrix, and require careful tuning of parameters such as the number of dimensions $D$ for proper regularisation.

This paper describes Bayesian models which are less prone to problems of overfitting, as well as being superior in performance to the aforementioned SVD algorithms. In section 2 we introduce the Probabilistic Matrix Factorization(PMF) algorithm, which uses MAP estimation on the simplest Bayesian model with a independent Gaussian distributions on each entry of $R$ along with independent Gaussian priors on the rows of U and V. In section 3 we give an extension of PMF called Bayesian PMF, which uses Monte Carlo estimation on a hierarchical Bayesian model. In section 4, we describe the Variational Bayesian approach (VB) which replaces MAP estimates of $U$,$V$ in PMF with their expectations, and uses variational inference to approximate these values. In section 5, we compare their empirical performances: their RMSE on the test set, the RMSE for ratings of infrequent users with less than 10 ratings, and the RMSE for different combinations of these algorithms. We also cover with caution the running times for these algorithms. Wherever possible we evaluate the results and offer possible explanations to provide insight for each algorithm. Finally in section 6, we discuss other models which deserve interest, such as those which use Restricted Boltzmann Machines and Gaussian Processes. We also provide further scope of research in the domain of large-scale collaborative filtering.

\section{Probabilistic Matrix Factorization (PMF)}

We use the notation in the Introduction, along with $U_i$ for row $i$ of $U$ and $V_j$ for row $j$ of $V$. Since we wish $U_i V_j^T$ to estimate $R_{ij}$, the most natural Bayesian model would begin with the following conditional distribution on each $R_{ij}$:
\begin{equation}
R_{ij}|{U_i},{V_j} \sim N(U_i V_j^T,\sigma^2)
\end{equation}

Also for simplicity in calculation, we assume that $R_{ij}$, conditioned on the values of $U$ and $V$, are independent random variables. Hence:

\begin{equation}
p(R|U,V)=\prod_{(ij)}\mathcal{N}(R_{ij}|U_i V_j^T,\sigma^2)
\end{equation}
where the product ranges over pairs of user/movie indices in the training set, and $\mathcal{N}(x|\mu,\sigma^2)$ is the probability density of the Gaussian distribution with mean $\mu$ and variance $\sigma^2$

The paper does not mention that although $R_{ij}$ is in fact a discrete, integer-valued random variable, it is modelled by a continuous distribution. This model is, however, justified as there is no requirement that the prediction must also be integer-valued. It is in fact beneficial to model $R_{ij}$ as a continuous random variable, since then non-integer part of the prediction would be helpful in distinguishing the top recommendations from the good ones.

Moreover we set $U$ and $V$ to be random variables, on which we put Gaussian priors with zero mean and spherical covariance (a multiple of the identity matrix):

\begin{equation}
p(U)=\prod_{i=1}^N \mathcal{N}(U_i|0,\sigma_U^2I) \hspace{10 mm} p(V)=\prod_{j=1}^M \mathcal{N}(V_j|0,\sigma_V^2I)
\end{equation}

These priors can be interpreted as a natural regularisation induced by our Bayesian model, which can help reduce overfitting. We will see below how the values of sigma can be interpreted as the degree of regularisation. Here one could also raise the issue whether it is sensible to use a spherical covariance as opposed to, say, a diagonal covariance or even a full covariance matrix. The paper confirms that empirically, this generalisation does not give much of an improvement in performance, hence the paper adheres to a spherical variance for the sake of simplicity. 

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale=0.3]{pmf_graphical_model}}
\end{center}
\caption{Graphical model for PMF[PMF]}
\end{figure}

By Bayes' Theorem, the log posterior of U and V can be calculated as:

\begin{equation}
\ln p(U,V|R)=-\frac{1}{2\sigma^2}\sum_{(ij)}(R_{ij}-U_iV_j^T)^2 - \frac{1}{2\sigma_U^2}\sum_{i=1}^N \|U_i\|_2^2-\frac{1}{2\sigma_V^2}\sum_{j=1}^M \|V_j\|_2^2 + C
\end{equation}

where $C$ is some constant independent of $U,V,R$. Maximising the log-posterior over $U$ and $V$ is then equivalent to minimising the sum of squared errors with quadratic regularisation terms:

\begin{equation}
E=\frac{1}{2}\sum_{(ij)}(R_{ij}-U_iV_j^T)^2 - \frac{\lambda_U^2}{2}\sum_{i=1}^N \|U_i\|_2^2-\frac{\lambda_V^2}{2}\sum_{j=1}^M \|V_j\|_2^2
\end{equation}

where $\lambda_U=\sigma^2/\sigma_U^2, \lambda_V=\sigma^2/\sigma_V^2$. Although unmentioned in the paper, this form of quadratic regularisation, as in ridge regression, is intuitively the type of regularisation we would want to avoid overfitting; with careful optimisation, $U$ and $V$ with large entries may have low error on observed entries of $R$. Then, however, predictions for unobserved entries can become extreme, and due to the extreme sparsity of $R$, this will become a major issue when trying to predict many ratings, as is the case for the Netflix Prize. So it is sensible to have $U$ and $V$ small by penalising their $L^2$ norms. This demonstrates that the use of a Gaussian prior on $U$ and $V$, and using a \textit{maximum a posteriori} (MAP) estimate is advantageous for three reasons. First, it automatically provides sensible and intuitive regularisation. Secondly, this approach to regularisation is much more flexible than simply penalising the $L^2$ norms of $U$ and $V$, since we may use priors with diagonal or even a full covariance matrix with adjustable means. And thirdly, the parameters whose values we need to fix is reduced from three ($\sigma$) to two ($\lambda$), making easier the tuning parameter selection and hence effective regularisation.

Now the objective in (5) is minimised with respect to $U$ and $V$ by gradient descent, hence $U,V$ converge to a stationary point: 

\begin{equation}
U_i^{(n+1)}=U_i^{(n)}-\epsilon \frac{\partial E}{\partial U_i}+\rho(U_i^{(n)}-U_i^{(n-1)}) 
\end{equation}
\begin{equation}
V_j^{(n+1)}=V_j^{(n)}-\epsilon \frac{\partial E}{\partial V_j}+\rho(V_j^{(n)}-V_j^{(n-1)}) 
\end{equation}

where $\epsilon$ is the learning rate and $\rho$ is the momentum term, which is used to avoid slow convergence due to heavy zig-zagging behaviour. Since $\nabla E$ is continuous, we may guarantee convergence to a local minimum by adjusting epsilon at each step of the iteration such that the Wolfe conditions are satisfied. However this is computationally demanding due to the large number of variables (>400,000 rows in $U$), so we use a constant learning rate. Moreover $E$ is not convex in $U$ nor $V$, so gradient descent does not guarantee convergence to the global minimum.

Instead of updating $U$ and $V$ after each epoch (sweep through the entire training set), we divide the data into mini-batches of size 100,000 and update $U,V$ after each batch in order to speed up training. Also since we are updating by going through the training set in order, it is important that we randomly permute the data after each epoch to avoid selection bias.

Through extensive experimentation, the paper claims that the use of values $\epsilon=0.005, \rho=0.9, \lambda_U=0.01, \lambda_V=0.001$ gives rise to best results. We use these values for the numerical experiments, the results of which are shown in section 5.

\begin{algorithm}
    \SetKwInOut{Input}{Input}
    \SetAlgoNoLine
    \caption{Probabilistic Matrix Factorization}
        \Input{training\_data,test\_data,$T,D,U,V,\Delta U,\Delta V$}
        \BlankLine
        Initialise $\epsilon,\lambda_U,\lambda_V,\rho ,numbatches$ \;
        \If{$U,V,\Delta U,\Delta V$ missing}{\label{lt}
            Initialise each entry of $U,V$ to $N(0,0.1^2)$ \;
            Initialise each entry of $\Delta U, \Delta V$ to 0 \;
        }
        \For{t=1:T}{
            permute training\_data \;
            \For{batch=1:numbatches}{
                pred\_out$\leftarrow$ predicted ratings for the user/movie pairs in batch, using current $U$ and $V$ \;
                $\frac{dE}{dU_i},\frac{dE}{dV_j}$ $\leftarrow$ 0 $\forall i,j$ \;
                Update $\frac{dE}{dU_i},\frac{dE}{dV_j}$ for user/movie pairs $i,j$ in batch, by adding on terms contributing to derivatives with respect to $U_i$ and $V_j$ respectively.
            }
            \For{i=1:N}{
                $\Delta U \leftarrow \rho\Delta U - \epsilon \frac{dE}{dU_i}$ \;
                $U \leftarrow U+\Delta U$ \;
                }
            \For{j=1:M}{    
                $\Delta V \leftarrow \rho\Delta V - \epsilon \frac{dE}{dV_j}$ \;
            $V \leftarrow V+\Delta V$ \;
            }
        }
\end{algorithm}

The paper suggests various modifications to the model. First it raises the point that with zero mean, diagonal covariance Gaussian priors on $U_i$ and $V_j$, the expected value of $U_iV_j^T$ is zero \textit{a priori}, whereas we would like a number between $1$ and $K$. Hence the paper suggests first mapping the ratings linearly to $[0,1]$ by $t(x)=\frac{x-1}{K-1}$ and modelling the mean of $R_{ij}|U_i,V_j$ as $sigmoid(U_iV_j^T)$, so that the expected value is 1/2 \footnote{One can show that $U_iV_j^T$ has a symmetric distribution about 0, and for $f$ an odd function about the line $y=a$, $X$ a symmetric random variable, $\mathbb{E}(f(X))=a$ } \textit{a priori}. Although the paper claims this modification renders an improved RMSE, we show later in section 5 through various experiments that not only is this computationally more expensive but also does not bring about better results, followed by a possible explanation of why this is. Furthermore, we discuss in section 6 an approach which tries to learn the function that should be applied to $U_iV_j^T$, using the non-parametric approach of Gaussian Processes.

Note that regularisation is ocurring in two different ways in our algorithm. Firstly, our choice of $D$ is crucial in controlling overfitting, since as mentioned in the Introduction, given sufficiently many factors the model can have arbitrarily small error on the training data. However the trouble with our Netflix data is that it is very imbalanced; the number of observations are significantly different over the rows and columns. Hence any single $D$ will be too high for some rows but too low for others, so there is a limit as to how effective this form of regularisation can be. So our second form of regularisation also plays an important role, which is through choosing the parameters $\lambda_U$ and $\lambda_V$. The simplest way to find suitable parameters would be to train each model on a set of candidate parameters, and choose the pair of values which gives the lowest RMSE. However this is computationally expensive as numerous models have to be trained. So the paper suggests a procedure called Adaptive Priors PMF, whereby priors are placed on $\sigma,\sigma_U,\sigma_V$, creating a hierarchial Bayesian model and so regularisation is now controlled by hyperparameters. More generally, we could place priors on the mean and variance parameters $\Theta_U, \Theta_V$ for $U,V$. Then an MAP estimate of $U,V,\sigma,\Theta_U,\Theta_V$ are obtained again by gradient descent on the following posterior:

\begin{equation}
\ln p(U,V,\Theta_U,\Theta_V|R)=\ln p(R|U,V)+\ln p(U|\Theta_U)+\ln p(V|\Theta_V)+\ln p(\Theta_U) +\ln p(\Theta_V) + C
\end{equation}

where C is a constant that does not depend on the parameters or the hyperparameters. We will further discuss this model in the next section on Bayes PMF. 


\section{Bayesian Probabilistic Factorization using Markov Chain Monte Carlo (BayesPMF)}

For the Bayesian PMF model, we build on the same conditional distribution for R as in the PMF model:

\begin{equation}
p(R|U,V)=\prod_{(ij)}\mathcal{N}(R_{ij}|U_i V_j^T,\alpha^{-1})
\end{equation}

One problem of the PMF model described in the previous section is the need for manual setting of the regularisation parameters $\lambda_U$ and $\lambda_V$, which is essential in controlling overfitting. So as suggested in the Adaptive Priors PMF model, it would be sensible to create a further level of parametrisation, by placing prior distributions over the parameters of $U$ and $V$, so that they are selected automatically by hyperparameters. In the BayesPMF model, however, the priors on $U$ and $V$ are now non-centered Gaussians, with further priors on both the mean and the precision, the inverse of the covariance matrix:

\begin{equation}
p(U)=\prod_{i=1}^N \mathcal{N}(U_i|\mu_U,\Lambda_U^{-1}) \hspace{10 mm} p(V)=\prod_{j=1}^M \mathcal{N}(V_j|\mu_V,\Lambda_V^{-1})
\end{equation}

\begin{equation}
\begin{split}
p(\Theta_U|\Theta_0) 
& = p(\mu_U|\Lambda_U)p(\Lambda_U) \\
& =\mathcal{N}(\mu_U|\mu_0,(\beta_0 \Lambda_U)^{-1})\mathcal{W}(\Lambda_U|W_0,\nu_0)
\end{split}
\end{equation}

\begin{equation}
\begin{split}
p(\Theta_V|\Theta_0) 
& = p(\mu_V|\Lambda_V)p(\Lambda_V) \\
& =\mathcal{N}(\mu_V|\mu_0,(\beta_0 \Lambda_V)^{-1})\mathcal{W}(\Lambda_U|W_0,\nu_0)
\end{split}
\end{equation}

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale=0.1]{bayespmf_graphical_model}}
\end{center}
\caption{Graphical model for BayesPMF[PMF]}
\end{figure}

Note that we have placed Gaussian-Wishart(G-W) priors on $\Theta_U={\mu_U,\Lambda_U}$ and $\Theta_V={\mu_V,\Lambda_V}$. This is because the G-W distribution is the conjugate prior to the Gaussian likelihood with unknown mean and unknown precision. In other words, this choice of prior ensures that the posterior of $\Theta_U$ and $\Theta_V$ are also G-W, making it easy to sample from these conditional distributions as we shall see later on.
We define  $\Theta_0=\{\mu_0,\nu_0,W_0,\beta_0\}$, and use the values $\mu_0=0,\nu_0=D,W_0=I,\beta_0=2,\alpha=2$ as in the paper.

Another potential problem of the PMF algorithm is that we use MAP estimates for $U$ and $V$, which is prone to overfitting as it finds a single point estimate of $U$ and $V$; it does not take into account all the information in the posterior distribution of $U$  and $V$. Hence although the model is Baysesian, the method of inference is similar to maximum-likelihood and not truely Bayesian. Instead, it would be beneficial to put a distribution on the parameters $\Theta_U$ and $\Theta_V$, and integrate out all random variables but R from the joint distribution to obtain its expected value.This is precisely what the paper attempts to do; the predictive distribution of a new rating $R_{ij}^*$ is obtained by integrating out $U,V$ and the model parameters from the joint:
\begin{equation}
p(R_{ij}^*|R,\Theta_0)=\iint p(R_{ij}^*|U_i,V_j)p(U,V|R,\Theta_U,\Theta_V)p(\Theta_U,\Theta_V|\Theta_0)d{U,V}d{\Theta_U,\Theta_V}
\end{equation}
Exact evaluation of this distribution is analytically intractable, hence we must rely on approximate inference using a Monte Carlo approximation:
\begin{equation}
p(R_{ij}^*|R,\Theta_0) \approx \frac{1}{T}\sum_{t=1}^T p(R_{ij}^*|U_i^{(t)},V_j^{(t)})
\end{equation}
where $T$ is the number of epochs for our algorithm. Here each sample $\{U_i^{(t)},V_j^{(t)}\}$ is generated by running a Markov chain with stationary distribution equal to the posterior of $\{U,V,\Theta_U,\Theta_V\}$. We use Gibbs sampling with a given number of jumps $J$ for each sample $\{U_i^{(t)},V_j^{(t)}\}$. MCMC methods are rarely used for large-scale learning as they are considered too computationally demanding. Nonetheless in this model, the use of G-W priors, which gives closed form posteriors and thus allows fast sampling from the posterior, gives rise to a computationally feasible implementation of Gibbs Sampling.

The conditional distribution of $U$ (and analogously for $V$) given all other random variables and hyperparameters is:

\begin{equation}
\begin{split}
p(U_i|R,V,\Theta_U,\alpha)
& = \mathcal{N}(U_i|\mu_i^*,[\Lambda_i^*]^{-1}) \\
& \sim \prod_{j \in N(i)} \mathcal{N}(R_{ij}|U_iV_j^T,\alpha^{-1})p(U_i|\mu_U,\Lambda_U)
\end{split}
\end{equation}
where
\begin{equation}
\Lambda_i^*=\Lambda_U+\alpha\sum_{j\in N(i)} V_j^TV_j
\end{equation}
\begin{equation}
\mu_i^*=(\Lambda_U\mu_U + \alpha\sum_{j\in N(i)} V_jR_{ij} )[{\Lambda_i^*}^T]^{-1}
\end{equation}


with a similar conditional distribution for $V$. Note that the conditional distribution over U factorises into a product of conditional distributions for each row $U_i$, and hence the sampler can easily be speeded up by sampling in parallel. This will indeed be a significant improvement since we must invert a $D$ by $D$ matrix for each sample of $U_i$, and $O(D^3)$ operation. There is a large number of users, hence this is the main bottleneck in reducing running-time. So we see how the independence assumptions for each entry of $R$ and each row of $U$ and $V$ are beneficial for computational reasons.

\begin{minipage}{\textwidth}
The conditional distribution of the parameters $\Theta_U$ (and analogously for $\Theta_V$) is given by the G-W distribution:

\begin{equation}
p(\mu_U,\Lambda_U|U,\Theta_0)=\mathcal{N}(\mu_U|\mu_0^*,(\beta_0^* \Lambda_U)^{-1})\mathcal{W}(\Lambda_U|W_0^*,\nu_0^*)
\end{equation}
where
\begin{equation}
\mu_0^*=\frac{\beta_0\mu_0+N\overline{U}}{\beta_0+N} \hspace{10 mm}
\beta_0^*=\beta_0+N
\hspace{10 mm}
\nu_0^*=\nu_0+N
\end{equation}
\begin{equation}
[W_0^*]^{-1}=W_0^{-1}+N\overline{S}+\frac{\beta_0N}{\beta_0+N}(\mu-\overline{U})(\mu-\overline{U})^T
\end{equation}
\begin{equation}
\overline{U}=\frac{1}{N}\sum_{i=1}^N U_i \hspace{10 mm} \overline{S}=\frac{1}{N}\sum_{i=1}^N (U_i-\overline{U})(U_i-\overline{U})^T
\end{equation}
\end{minipage}

\begin{algorithm}
    \SetKwInOut{Input}{Input}
    \SetAlgoNoLine
    \caption{Bayesian Probabilistic Matrix Factorization using MCMC}
        \Input{training\_data,test\_data,$T,D,J,U,V$ (Use U,V obtained from PMF) }
        \BlankLine
        Initialise $\alpha,\mu_U,\mu_V,\Lambda_U,\Lambda_V,W_0, \beta_0,\nu_0,\mu_0$ \;
        Initialise each prediction = prediction of user/movie pairs in test\_data for initial $U$ $V$ \;
        \For{t=1:T}{
            sample $\Theta_U^t=\{\mu_U^{(t)},\Lambda_U^{(t)}\}$ from the G-W posterior distribution $p(\Theta_U|U,\Theta_0$) \;
	        sample $\Theta_V^t=\{\mu_V^{(t)},\Lambda_V^{(t)}\}$ from the G-W posterior distribution $p(\Theta_V|V,\Theta_0$) \;
            \For{n=1:J}{
                \For{i=1:N}{ 
                    sample $U_i^{(t+1)}$ from the the posterior $p(U_i|R,V^{(t)},\Theta_V^{(t)})$  \tcp*[r]{parallelisable} 
                }
                \For{j=1:M}{ 
                    sample $V_j^{(t+1)}$ from the the posterior $p(V_j|R,U^{(t+1)},\Theta_V^{(t)})$  \tcp*[r]{parallelisable} 
                }
            }
            prediction $\leftarrow$ prediction + prediction from the update of $U,V$ \;
        }
        prediction $\leftarrow$ prediction/($T+1$) \;
\end{algorithm}

Note that we provide the output of PMF as the initial values for U and V in our algorithm. There is scope for experimentation by initialising U and V differently.

\section{Variational Bayesian Approach to Movie Rating Prediction (VB)}

The model for this new approach is precisely the model in PMF with diagonal covariance priors on $U$ and $V$. Note the change of notation:

\begin{equation}
p(R|U,V)=\prod_{(ij)}\mathcal{N}(R_{ij}|U_i V_j^T,\tau)
\end{equation}
\begin{equation}
p(U)=\prod_{i=1}^N \mathcal{N}(U_i|0,\Sigma) \hspace{10 mm} p(V)=\prod_{j=1}^M \mathcal{N}(V_j|0,P)
\end{equation}

where $\Sigma=diag(\sigma_1,...,\sigma_D), P=diag(\rho_1,...,\rho_D)$.

The novelty of this approach is that we use a different method for inference. We mentioned in the last section that a problem of the PMF algorithm is that it uses an MAP estimate $argmax_{U,V} p(U,V|R)$ for $U$ and $V$. These are point estimates, which are prone to overfitting. So in the BayesPMF algorithm, we used MCMC to estimate the expected value of $R$ by integrating out all other random variables from the joint. For the VB approach, we attempt to estimate instead the values $\hat{U}=\mathbb{E}(U|R)$ and $\hat{V}=\mathbb{E}(V|R)$, and use $\hat{U_i} \hat{V_j}^T$ as the prediction for $R_{ij}$. Now in order to evaluate these expectations, we need to be able to compute:

\begin{equation}
p(U,V|R)=\frac{p(R|U,V)p(U)p(V)}{p(R)}=\frac{p(R|U,V)p(U)p(V)}{\int_{U,V} p(R|U,V)p(U)p(V)}
\end{equation}

However the denominator is both analytically and computationally intractable due to the high dimensionality of $U$ and $V$, hence exact inference is not possible. Hence we resort to variational inference where we lower bound the marginal log-likelihood and try to maximise this bound, while at the same time using and approximation $Q(U,V)$ of $p(U,V|R)$ to estimate $\mathbb{E}(U|R)$ and $\mathbb{E}(V|R)$. The \textit{variational free energy} [1 in VB] is:

\begin{equation}
\mathcal{F}(Q(U,V))=\mathbb{E}_{Q(U,V)}[\log p(R,U,V) - \log Q(U,V)]
\end{equation}

The variational free energy is a lower bound on the log-likelihood $p(R)$ for all distributions $Q(U,V)$:

\begin{equation}
\begin{split}
\mathcal{F}(Q(U,V)) & = \mathbb{E}_{Q(U,V)}[\log p(R) + \log p(U,V|R) - \log Q(U,V)] \\ & = \log p(R) - KL(Q(U,V)\|p(U,V|R)) \\
& \leq \log p(R)
\end{split}
\end{equation}

where $Q(U,V)$ is an arbitrary distribution over $U$ and $V$, and $KL(q||p)=\int q(x)log\frac{q(x)}{p(x)}dx$ is the \textit{Kullback-Leibler(KL) divergence} from $q$ to $p$, a measure of information lost when $p$ is used to approximate $q$. Although this interpretation is not so intuitive and requires understanding of entropy in information theory, it relates to a more intuitive measure-theoretic notion of distance between two measures, called \textit{total variational distance}, by \textit{Pinsker's Inequality}:

\begin{def*}[Total Variational Distance] 
For $P,Q$ two probability measures on measure sapce $(\chi,\mathcal{A})$ we define the \textit{total variational distance} $\|P-Q\|_{TV}=\sup\limits_{A\in\mathcal{A}}|P(A)-Q(A)|$
\end{def*}

\begin{lemma*}[Pinsker's Inequality]
Suppose $P,Q$ have a common dominating measure $\mu$ in $(\chi,\mathcal{A})$. Then
\begin{center}
$\|P-Q\|_{TV} \leq \sqrt{\frac{1}{2}KL(P||Q)}$
\end{center}
\end{lemma*}

Hence we see that maximising $\mathcal{F}(Q(U,V))$ with respect to $Q(U,V)$, and hence minimising the KL divergence from $Q(U,V)$ to $P(U,V|R)$, is sensible when trying to approximate $P(U,V|R)$ with $Q(U,V)$.Now $KL(P\|Q) \geq 0$ for all distributions $P,Q$, with equality if and only if $P \equiv Q$, known as \textit{Gibb's Inequality} in information theory. Hence the minimiser of the KL divergence from $Q(U,V)$ to $P(U,V|R)$ is $P(U,V|R)$ itself. However we have from above that $P(U,V|R)$ is intractable, hence this global minimiser of the KL divergence is not what we desire. We want instead something similar to a "local minimum" but in the infinite dimensional space of all distributions. A common practice in Bayesian variational inference when the posterior is intractable, is to constrain the approximator $Q$ to be of a particular form, and minimise the KL divergence with respect to $Q$ subject to this constraint, so that equality is not achieved above. The paper applies the \textit{mean field} approximation where $Q(U,V)$ is assumed to take the form $Q(U)Q(V)$. In other words, the posteriors of $U$ and $V$ are assumed to be independent when searching for the approximation. The reasoning behind using this constraint, apart from being simple and perhaps most natural, is that it makes the minimiser of KL divergence computationally tractable, so that we can find a closed form iterative scheme to approximate the minimising $Q(U,V)$. 
\begin{minipage}{\textwidth}
\begin{equation}
\begin{split}
\mathcal{F}(Q(U)Q(V)) 
& =\mathbb{E}_{Q(U)Q(V)}\Bigg[  -\frac{1}{2}\left(\sum_{i=1}^N\sum_{l=1}^D \log (2\pi\sigma_l^2)+\frac{u_{il}^2}{\sigma_l^2}\right) -\frac{1}{2}\left(\sum_{j=1}^M\sum_{l=1}^D \log (2\pi\rho_l^2)+\frac{v_{jl}^2}{\rho_l^2}\right) \\
& \hspace{5 mm} -\frac{1}{2}\left(\sum_{(ij)} \log (2\pi\tau^2)+\frac{(R_{ij}-U_iV_j^T)^2}{\tau^2}\right)-\log Q(U) -\log Q(V) \Bigg] \\
& = -\frac{L}{2} \log (2\pi\tau^2)-\frac{N}{2}\sum_{l=1}^D \log (2\pi\sigma_l^2) - \frac{M}{2}\sum_{l=1}^D \log (2\pi\rho_l^2) \\
& \hspace{5 mm} -\frac{1}{2}\sum_{l=1}^D \left(\frac{\sum_{i=1}^N \mathbb{E}_{Q(U)}[U_{il}^2]}{\sigma_l^2} +\frac{\sum_{j=1}^M \mathbb{E}_{Q(V)}[V_{jl}^2]}{\rho_l^2}\right) \\
& \hspace{5 mm} -\frac{1}{2} \sum_{(ij)}\frac{\mathbb{E}_{Q(U)Q(V)}[(R_{ij}-U_iV_j^T)^2]}{\tau^2} -\mathbb{E}_{Q(U)} \log Q(U) - \mathbb{E}_{Q(V)} \log Q(V)
\end{split}
\end{equation}
\end{minipage}

where $L$ is the total number of observations in the training data. To maximise the above we may simply maximise with respect to $Q(U)$ and $Q(V)$ separately, optimising one keeping the other fixed, and iterating until convergence. For this we use Lagrange Multipliers so that $\mathcal{F}(Q(U)Q(V))$ is maximised in $Q(U)$ subject to $\int Q(U) dU =1$ and similarly for $Q(V)$. This gives:

\begin{minipage}{\textwidth}
\begin{equation}
Q(U) \propto \prod_{i=1}^N \exp\left(-\frac{1}{2}(U_i-\overline{U_i})\Phi_i^{-1}(U_i-\overline{U_i})^T\right)
\end{equation}
where
\begin{equation}
\Phi_i = \left(diag\left(\frac{1}{\sigma_1^2} , ... , \frac{1}{\sigma_D^2}\right)+\sum_{j \in N(i)} \frac{\Psi_j+\overline{V_j}^T\overline{V_j}}{\tau^2}\right)^{-1} \hspace{10 mm} \overline{U_i} = \left(\sum_{j\in N(i)} \frac{R_{ij}\overline{V_j}}{\tau^2} \right)\Phi_i^T 
\end{equation}
\end{minipage}

where $\overline{V_j}=\mathbb{E}_{Q(V)}[V_j], \Psi_j=\mathrm{Var}_{Q(V)}[V_j]$ and $N(i)$ is the set of $j$'s such that $R_{ij}$ is observed, with an analogous equation for $Q(V)$.

In the algorithm, we approximate $\overline{V_j}$ by the current value of $V_j$ and set $\Psi_j$ as $\frac{1}{D}I$ where I is the identity matrix, the reasoning for which we will see below.

However, this assumption that the posterior of $U$ and $V$ are independent is difficult to justify since $U_i$ and $V_j$ depend heavily on each other through the observed rating $R_{ij}$. Hence due to this crude approximation we may face performance losses on the test set, which is the main drawback of this variational algorithm.

The VB algorithm does not only maximise $\mathcal{F}(Q(U)Q(V))$ with respect to $Q(U),Q(V)$, but also tries to learn the variance parameters $\Theta=\{\tau,\mathbf{\sigma},\mathbf{\rho} \}$. This is done by alternating the above maximisation of $\mathcal{F}(Q(U)Q(V))$ with respect to $Q(U)$ and $Q(V)$ with the maximisation (of the same objective) with respect to $\Theta$. By setting each of the derivatives to 0, we get the maximisers:

\begin{equation}
\sigma_l^2=\frac{1}{N-1}\sum_{i=1}^N (\Phi_i)_{ll}+\overline{U_i}_l^2 
\end{equation}
\begin{equation}
\rho_l^2=\frac{1}{M-1}\sum_{j=1}^M (\Psi_j)_{ll}+\overline{V_j}_l^2
\end{equation}
\begin{equation}
\tau^2=\frac{1}{L-1}\sum_{(ij)} R_{ij}^2-2R_{ij}\overline{U_i}\overline{V_j}^T+tr[(\Phi_i+\overline{U_i}^T\overline{U_i})(\Psi_j+\overline{V_j}^T\overline{V_j})]
\end{equation}

Here we note that the VB algorithm is a \textit{Generalised Expectation-Maximisation}\ algorithm applied to the hidden variables $Q(U),Q(V)$ and the set of parameters $\Theta$. For the E-step, we maximise $\mathcal{F}(Q(U)Q(V))$ with respect to $Q(U),Q(V)$ by minimising $KL(Q(U)Q(V)||P(U,V|R))$, and for the M-step we maximise $\mathcal{F}(Q(U)Q(V))$ with respect to $\Theta$. For each step $\mathcal{F}(Q(U)Q(V))$ always increases, with log-likelihood staying the same for the E-step, whereas the KL divergence and log-likelihood may either increase or decrease for the M-step, since both are parametrised by $\Theta$. Figure 3 displays the algorithm visually.

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[scale=0.1]{variational_inference_figure}}
\end{center}
\caption{Variational interpretation of constrained E-M. In the E-step the hidden variable posterior ${q_\boldsymbol{x}} ^{(t+1)}(x)$ is set to the minimiser of $KL({q_\boldsymbol{x}}(x) \|p(\boldsymbol{x}|\boldsymbol{y},\boldsymbol{\theta}^{(t)}))$ subject to $q_\boldsymbol{x}$ lying in the family of constrained distributions. In the M-step the parameters $\boldsymbol{\theta}^{(t+1)}$ are set to maximise $\mathcal{F}({q_\boldsymbol{x}} ^{(t+1)},\boldsymbol{\theta})$ [Variational Algorithms for Approximate Bayesian Inference] } %
\end{figure}

The maximisation of $\mathcal{F}(Q(U)Q(V))$ with respect to $Q(U),Q(V)$ and $\Theta$ can be seen as a type of maximum-likelihood approach with penalisation by how much $Q(U)Q(V)$ and $P(U,V|R)$ differ, their KL divergence. By maximising $\mathcal{F}(Q(U,V))$ with respect to both sets of arguments, we are trying to maximise the likelihood such that $KL(Q(U)Q(V)||P(U,V|R))$ does not get too large, which is reasonable since we wish to learn $\Theta$ so that it fits the data well but at the same time wish to learn $Q(U)Q(V)$ to be a good approximator for $P(U,V|R)$.

In summary, the variational algorithm runs as follows:
\newpage
\textbf{E-step}: \\
1. Initialise $S_j$ and $t_j$ for $j=1,...,M$:
\begin{equation}
S_j \leftarrow diag\left(\frac{1}{\sigma_1^2} , ... , \frac{1}{\sigma_D^2}\right) \hspace{10 mm} t_j \leftarrow 0_{D \times 1}
\end{equation}
2. Update $Q(U_i$) for $i=1,...,N$: \\
   a) Compute $\Phi_i$ and $\overline{U_i}$:
\begin{equation}
\Phi_i \leftarrow \left(diag\left(\frac{1}{\sigma_1^2} , ... , \frac{1}{\sigma_D^2}\right)+\sum_{j \in N(i)} \frac{\Psi_j+\overline{V_j}^T\overline{V_j}}{\tau^2}\right)^{-1}
\end{equation}
\begin{equation}
\overline{U_i} \leftarrow \left(\sum_{j\in N(i)} \frac{R_{ij}\overline{V_j}}{\tau^2} \right)\Phi_i^T
\end{equation}
   b) Update $S_j$ and $t_j$ for $j \in N(i)$:
\begin{equation}
S_j \leftarrow S_j+\frac{\Phi_i+\overline{U_i}^T\overline{U_i}}{\tau^2} \hspace{10 mm} t_j \leftarrow t_j+\frac{R_{ij}\overline{V}}{\tau^2}
\end{equation}
3. Update $Q(V_j)$ for $j=1,...,M$:
\begin{equation}
\Psi_j \leftarrow S_j^{-1} \hspace{10mm} \overline{V_j} \leftarrow \Psi_j t_j
\end{equation}
\textbf{M-step}: \\
Update $\sigma_l,\rho_l,\tau$ for $l=1,...,D$:
\begin{equation}
\sigma_l^2=\frac{1}{N-1}\sum_{i=1}^N (\Phi_i)_{ll}+\overline{U_i}_l^2 
\end{equation}
\begin{equation}
\rho_l^2=\frac{1}{M-1}\sum_{j=1}^M (\Psi_j)_{ll}+\overline{V_j}_l^2
\end{equation}
\begin{equation}
\tau^2=\frac{1}{L-1}\sum_{(ij)} R_{ij}^2-2R_{ij}\overline{U_i}\overline{V_j}^T+tr[(\Phi_i+\overline{U_i}^T\overline{U_i})(\Psi_j+\overline{V_j}^T\overline{V_j})]
\end{equation}

The variables that need to be stored for each E-M step are $\{\Phi_i,\overline{U_i},\Psi_j,\overline{V_j} : \forall i\in \{1,...,N\},j\in \{1,...,M\}\}$. Note however that the number of users $N>400,000$ and each $\Phi_i$ is of size $D \times D$, so we will not have enough memory to store all the $\Phi_i$'s. To alleviate this, we instead use $\Phi_i$ wherever it is required as soon as it is computed, then we discard it immediately for each $i\in \{1,...,N\}$. Note however that $\{\Psi_j : \forall j\in \{1,...,M\} \}$ can be stored, since $M<20,000$. As we shall see in the pseudocode below, all that is needed to initialise VB is $U,V,\Psi,\mathbf{\sigma}$ and $\tau$. Also, instead of using $S_j$ and $t_j$ we update as we go $\Psi$ and $V'$, a container for the updated $V$.If initial values of $U$ and $V$ are unspecified, we initialise them such that each entry is sampled independently from the standard Gaussian.

We shall initialise Also note that we have $D$ spare degrees of freedom when choosing $U$ and $V$, since multiplying a column of $U$ by $c$ and dividing the corresponding column of $V$ by $c$, the product $UV^T$ is identical. Thus we may keep $\rho_l^2=\frac{1}{D}$ fixed, and initialise $U$ and $V$ by normalising each column of $V$ so that it has $L^2$ norm $\frac{1}{\sqrt{D}}$ and multiplying each column of U by an appropriate factor to keep $UV^T$ the same. Then since $diag(\sigma_1,...,\sigma_D)$ is meant to the covariance of each $U_i$ we initialise $\boldsymbol{\sigma}$ to be the diagonal terms of the sample covariance of the $U_i$'s. $\tau^2$ is initialised to 0.456 through experimentation according to the paper.

\newpage
\begin{algorithm}
    \SetKwInOut{Input}{Input}
    \SetAlgoNoLine
    \caption{Variational Bayes}
        \Input{training\_data,test\_data,$T,D$}
        \BlankLine
        Initialise $U_i,V_j,\Psi_j,\tau,\boldsymbol{\sigma} \hspace{2mm} \forall i\in \{1,...,N\},j\in \{1,...,M\}$ with suitable normalisations applied to columns of $U$ and $V$ \;
        \For{t=1:T}{
            \For{j=1:M}{
                Initialise $V'_j$ to a row vector of $D$ zeros \tcp*[r]{container for new $V_j$} 
		        Set $\Gamma_j=\Psi_j+V_jV_j^T$\;
		        $\Psi_j \leftarrow DI_D$\;
            }
            Initialise $\boldsymbol{\sigma}_{new}$ to a column vector of $D$ zeros \;
	        Initialise $\tau_{new}$ to 0 \;
            \For{i=1:N}{
                Set $\Phi=\left( diag(\boldsymbol{\sigma})+\sum_{j \in N(i)}  \frac{\Gamma_j}{\tau^2} \right)^{-1}$ \;
		        Set $U'=\left( \sum_{j \in N(i)} \frac{R_{ij}V_j}{\tau^2} \right)\Phi^T$ \tcp*[r]{container for new $U_i$} 
		        Set $\Omega=\Phi+U'U^T$ \;
		        $\sigma_{new}=\boldsymbol{\sigma}_{new}+U'^T.^2+diag(\Phi)$ \tcp*[r]{$.^2$ squares vector elementwise} 
                \For{j \in N(i)}{
                    $\Psi_j \leftarrow \Psi_j+\frac{\Omega}{\tau}$ \;
			        $V'_j \leftarrow V'_j+\frac{R_{ij}U'}{\tau}$ \;
			        $\tau_{new} \leftarrow \tau_{new}+tr(\Omega\Gamma_j)+R_{ij}^2-2R_{ij}V_j U'^T$ \;
                }
                $U_i \leftarrow U'$ \;
            } 
            \For{j=1:M}{
		        $\Psi_j \leftarrow (\Psi_j)^{-1}$ \;
		        $V_j \leftarrow V'_j \Psi_j$ \;
		    }
	        $\boldsymbol{\sigma}\leftarrow \frac{\boldsymbol{\sigma}_{new}}{N-1}$ \;
	        $\tau \leftarrow \frac{\tau_{new}}{L-1}$ \;
        }
\end{algorithm}
Note that the time complexity for each epoch of the algorithm is $O(L+MD^3+ND^3)$, where the $D^3$ comes from the inversion of a $D \times D$ matrix. Having to compute this for each user is the bottleneck for the algorithm.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\iffalse

[[[[[[[[[[[[still need to sort out references]]]]]]]]]]]]

The formatting instructions contained in these style files are summarized in
sections \ref{gen_inst}, \ref{headings}, and \ref{others} below.

\subsection{Keywords for paper submission}
%% Your NIPS paper can be submitted with any of the following keywords (more than one keyword is possible for each paper):

 \begin{verbatim}
 Bioinformatics
 Biological Vision
 Brain Imaging and Brain Computer Interfacing
 \end{verbatim}

%% A description of each keyword can be found in the call for papers at
%% the author instruction web site (http://research.microsoft.com/conferences/nips06/)

\section{General formatting instructions}
\label{gen_inst}

Please pay special attention to the instructions in section \ref{others}
regarding figures, tables, acknowledgments, and references.


\section{Citations, figures, tables, references}
\label{others}

These instructions apply to everyone, regardless of the formatter being used.

\subsection{Citations within the text}

Citations within the text should be numbered consecutively. The corresponding
number is to appear enclosed in square brackets, such as [1] or [2]-[5]. The
corresponding references are to be listed in the same order at the end of the
paper, in the \textbf{References} section. (Note: the standard
\textsc{Bib\TeX} style \texttt{unsrt} produces this.) As to the format of the
references themselves, any style is acceptable as long as it is used
consistently.

\subsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first footnote} in the
text. Place the footnotes at the bottom of the page on which they appear.
Precede the footnote with a horizontal rule of 2~inches
(12~picas).\footnote{Sample of the second footnote}

\subsection{Figures}

All artwork must be neat, clean, and legible. Lines should be dark enough for
purposes of reproduction; art work should not be hand-drawn. Figure number and
caption always appear after the figure. Place one line space before the figure
caption, and one line space after the figure. The figure caption is lower case
(except for first word and proper nouns); figures are numbered consecutively.

Make sure the figure caption does not get separated from the figure.
Leave sufficient space to avoid splitting the figure and figure caption.

You may use color figures. However, please note that the archival version
of the final proceedings are printed in greyscale. It is best for the
figure captions and the paper body to make sense if the paper is printed
either in black/white or in color.
\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption}
\end{figure}

\subsection{Tables}

All tables must be centered, neat, clean and legible. Do not use hand-drawn
tables. Table number and title always appear before the table. See
Table~\ref{sample-table}.

Place one line space before the table title, one line space after the table
title, and one line space after the table. The table title must be lower case
(except for first word and proper nouns); tables are numbered consecutively.

\begin{table}[t]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\section{Final instructions}
Do not change any aspects of the formatting parameters in the style files. In
particular: do not modify the width or length of the rectangle the text should
fit into, and do not change font sizes (except perhaps in the
\textbf{References} section; see below). Leave pages unnumbered.

\section{Preparing PostScript or PDF files}

Please prepare PostScript or PDF files with paper size ``US Letter'', and
not, for example, ``A4''. The -t
letter option on dvips will produce US Letter files.

Fonts were the main cause of problems in the past years. Your PDF file must
only contain Type 1 or Embedded TrueType fonts. Here are a few instructions
to achieve this.

\begin{itemize}

\item You can check which fonts a PDF files uses. In Acrobat Reader, select
menu Files$>$Document Properties$>$Fonts and select Show All Fonts. You can
also use the program \verb+pdffonts+ which comes with \verb+xpdf+ and is
available out-of-the-box on most Linux machines.

\item The IEEE has recommendations for generating PDF files whose fonts
are also acceptable for NIPS. Please see
http://www.icip2004.org/Downloads/IEEE-PDF-SpecV32.pdf

\item LaTeX users:

\begin{itemize}

\item For MiKTeX users, please consider directly generating PDF files using
\verb+pdflatex+. PDF figures must be substituted for EPS figures,
however.

\item Otherwise, please generate your PostScript and PDF files with the following commands:
\begin{verbatim} 
dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
ps2pdf mypaper.ps mypaper.pdf
\end{verbatim}

Check that the PDF files only contains Type 1 fonts. For the camera-ready version, please send us both the Postscript file and the PDF file.

\item xfig "patterned" shapes are implemented with 
bitmap fonts.  Use "solid" shapes instead. 
\item The \verb+\bbold+ package almost always uses bitmap
fonts.  You can try the equivalent AMS Fonts with command
\begin{verbatim}
\usepackage[psamsfonts]{amssymb}
\end{verbatim}
 or use the following workaround for reals, natural and complex: 
\begin{verbatim}
\newcommand{\RR}{I\!\!R} %real numbers
\newcommand{\Nat}{I\!\!N} %natural numbers 
\newcommand{\CC}{I\!\!\!\!C} %complex numbers
\end{verbatim}

\item Sometimes the problematic fonts are used in figures
included in LaTeX files. The ghostscript program \verb+eps2eps+ is the simplest
way to clean such figures. For black and white figures, slightly better
results can be achieved with program \verb+potrace+.
\end{itemize}
\item MSWord and Windows users:
\begin{itemize}
\item Install the AdobePS printer driver and Adobe Distiller PPD file from
http://www.adobe.com/support/techdocs/325924.html, to create a new printer
on your computer. {\it Note:} You must reboot your PC after installing the
AdobePS driver for it to take effect.
\item To produce the ps file, select ``Print'' from the MS app, choose
the installed AdobePS printer, click on ``Properties'', click on ``Advanced.''
\item Set ``TrueType Font'' to be ``Download as Softfont''
\item Open the ``PostScript Options'' folder
\item Select ``PostScript Output Option'' to be ``Optimize for Portability''
\item Select ``TrueType Font Download Option'' to be ``Outline''
\item Select ``Send PostScript Error Handler'' to be ``No''
\item Click ``OK'' three times, print your file.
\end{itemize}
\item Now, use Adobe Acrobat Distiller or ps2pdf to create a PDF file from
the PS file. In Acrobat, check the option ``Embed all fonts'' if
applicable.

\end{itemize}
If your file contains Type 3 fonts or non embedded TrueType fonts, we will
ask you to fix it. 

\subsection{Margins in LaTeX}
 
Most of the margin problems come from figures positioned by hand using
\verb+\special+ or other commands. We suggest using the command
\verb+\includegraphics+
from the graphicx package. Always specify the figure width as a multiple of
the line width as in the example below
\begin{verbatim}
   \usepackage[dvips]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.eps} 
\end{verbatim}
See section 4.4 in the graphics bundle documentation (http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps) 
 
A number of width problems arise when LaTeX cannot properly hyphenate a
line. Please give LaTeX hyphenation hints using the \verb+\-+ command.


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper.

\subsubsection*{References}

References follow the acknowledgments. Use unnumbered third level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to `small' (9-point) 
when listing the references.

\small{
[1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
and T.K. Leen (eds.), {\it Advances in Neural Information Processing
Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

[2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
Realistic Neural Models with the GEneral NEural SImulation System.}
New York: TELOS/Springer-Verlag.

[3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
and recall at excitatory recurrent synapses and cholinergic modulation
in rat hippocampal region CA3. {\it Journal of Neuroscience}
{\bf 15}(7):5249-5262.
}
\fi
\end{document}
