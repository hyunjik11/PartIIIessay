ABSTRACT

Collaborative filtering defines a branch of techniques for tackling the following supervised learning problem: 
making predictions(filtering) about the preferences of a user, based on information regarding the preference of many users (collaborating).
Having obtained such predictions, it is then a simple task to build a recommender system for users; we simply recommend the items with highest preference by a given user.
In this paper, we first introduce the three most successful Bayesian algorithms for collaborative filtering on the Netflix dataset. These are Probabilistic Matrix Factorization (PMF), its variant Bayesian PMF(BPMF), and Variational Bayes (VB). We describe their mechanisms in full, fleshing out the missing details in the original papers. We then give results of authentic numerical experiments for direct comparison of their empirical performances, as well as speed. Moreover we investigate their performances on a small subset of the data for users with few movie ratings, where prediction is known to be most difficult. Finally, we show results of experiments using combinations of these algorithms for improved performance on the Netflix data.

Comments: Would be nice to include some results in the abstract.

INTRODUCTION

Prediction of user ratings applies to various contexts, such as for online videos, books and other commercial products. In this paper, we will focus on movie ratings by users provided by the Netflix dataset, the largest publicly available movie rating data. This was publicised during the Netflix Prize in 2009, a competition organised by Netflix for the most accurate recommender system that predicts user ratings, given the user rating history [2 in VB]. Netflix provided just over 100,000,000 ratings from around 480,000 randomly chosen users and around 18,000 movies which they have rated, collected between 1998 and 2005. The task is to predict a prespecified set of 3 million unobserved ratings (test set) from these users over these movies. The metric for error is the root mean-squared error (RMSE) over the test set. We use Cinematch, Neflix's own system, with RMSE 0.9474 as a baseline.

Let us introduce some notation and terminology to begin with. Let there be N users with M movies. Each user u_i rates movie m_j with rating R_ij /in {1,...,K}. Hence the rating matrix R is incomplete. In fact, it is incredibly sparse as most users will only have rated a small fraction of the total set of movies. Collaborative filtering aims to fill R by only using the already filled entries (observed ratings) of R. The underlying assumption for this matrix completion that if user A has a similar rating as user B on a movie, then A is more likely to share B¡¯s rating on a different movie than another user selected at random. 

This approach is contrary to content-based filtering, which predicts user ratings based on attributes of movies such as genre,number of viewings,director,cast etc. There are several drawbacks of content-based filtering, such as limited content analysis and over-specialisation, but the main difficulty in applying content-based filtering to a dataset as large as the Netflix data is that it requires building user profiles; this highly memory intensive task is unsuitable for large data sets. Also it is not so clear as to how detailed the profiles should be made and how the weights should be given to different attributes of films. This is why the vast majority of approaches to the Netflix problem are based on collaborative filtering, which deals with a problem of reduced complexity, and thus can be seen as a step towards automation.

Collaborative filtering can further be classified into two approaches: memory-based and model-based. The former uses the rating data  to calculate similarities between users or between movies, and makes predictions based on these similar users/movies, called neighbours. Then a certain function of the similarity and observed ratings is used to predict ratings. A popular example would be k-NN, where a weighted average of the k nearest neighbours' ratings on a movie is the prediction. The similarity measure used is normally not a metric as the triangle inequality does not hold (two users with preferences dissimilar to a third user may have similar preferences). This implies that we need a similarity measure between all pairs of users, the number of which is O(N^2), hence giving rise to scalability issues for big data such as the Netflix dataset. Moreover the sparsity of the data implies that there could only be a handful of truely similar users, severely limiting the set of movies for which a sensible prediction can be made. A more fundamental problem is that there is no explicit statistical model, so very little insight in the data is gained when creating a memory-based prediction system. 

On the other hand, model-based collaborative filtering methods use the rating data to train a statistical model, which can then be used to make predictions. There have been various models in the literature even before the Netflix Prize, notably cluster based models ([5,6,7,8] of CL via Gaussian PLSA paper) and probabilistic models such as [Gaussian pLSA]. These algorithms seem to show impressive results on standard datasets such as MovieLens and EachMovie. However we must bear in mind that these datasets have had all users with fewer ratings than a lower threshold removed, which are intuitively the most difficult cases. The Netflix data, on the other hand, is very imbalanced: there coexist infrequent users with less than 5 ratings and frequent users with more than 10,000 ratings. Moreover the previously mentioned data sets are orders of magnitudes smaller than the Netflix data in size, and it has become apparent that scalability is also one of the main issues with these existing models.

The breakthrough for scalable model-based approaches was the clever idea of applying matrix factorisation to the rating matrix. We factorise the N by M rating matrix R as a product of two matrices U and V^T, where U and V are N by D and M by D respectively, where D is a positive integer to be chosen. They are referred to as the user matrix and the movie matrix. Instead of learning R directly, we build a model for R in terms of U and V, and try to learn U and V so that the error on the observed ratings is minimised. Then we simply fill in the blanks of R by multiplying out U and V^T. The intuition behind this model is that there are only a few factors which affect the user's rating of a movie. So each row of V can be interpreted as the D features of a movie which affect the rating of users, and then each row of U would correspond to the user's weights given to each feature. Note here that the choice of a suitable dimension D is important. If D is large, we will always be able to choose U and V such that we have perfect predictions on observed ratings, the training data. This hence leads to overfitting, as well as being computationally infeasible. So we want D to be small, but not too small as then it might not capture all the different features responsible for a rating.

From a mathematical point of view, we note that if R=UV', then rank(R)<=D. Hence finding U and V is equivalent to finding the best rank D approximation to R, in the squared error sense. It is a standard result in linear algebra that this can easily be obtained from the Singular Value Decomposition (SVD) of R, commonly referred to as the Matrix Approximation Lemma [The approximation of one matrix by another of lower rank].

Here: Equations for SVD in latex.

However, the problem with our rating matrix is that it is incomplete - some entries are missing. The above result holds for R complete. This seemingly small modification results in a non-convex optimisation problem, and an approach different to standard SVD computation needs to be employed. Nonetheless there do exist SVD extensions which deal successfully with this problem, such as the use of the EM algorithm where the unobserved entries are modelled as latent variables [10 of VB], Gradient Boosting with successive rank 1 updates to U and V, and many other variants. These approaches have shown to be successful on the Netflix data. However, these procedures have also shown to overfit easily due to the extreme sparsity of the rating matrix, and require careful tuning of parameters such as the number of dimensions D for proper regularisation.

This paper describes Bayesian models which are less prone to problems of overfitting, as well as being superior in performance to the aforementioned SVD algorithms. In section 2 we introduce the Probabilistic Matrix Factorization(PMF) algorithm, which uses MAP estimation on the simplest Bayesian model with a independent Gaussian distributions on each entry of R along with independent Gaussian priors on the rows of U and V. In section 3 we give an extension of PMF called Bayesian PMF, which uses Monte Carlo estimation on a hierarchial Bayesian model. In section 4, we describe the Variational Bayesian approach (VB) which replaces MAP estimates of U,V in PMF with their expectations, and uses variational inference to approximate these values. In section 5, we compare their empirical performances: their RMSE on the test set, the RMSE for ratings of infrequent users with less than 10 ratings, and the RMSE for different combinations of these algorithms. We also cover with caution the running times for these algorithms. Wherever possible we evaluate the results and offer possible explanations to provide insight for each algorithm. Finally in section 6, we discuss other models which deserve interest, such as those which use Restricted Boltzmann Machines and Gaussian Processes. We also provide further scope of research in the domain of large-scale collaborative filtering.

PROBABILISTIC MATRIX FACTORIZATION (PMF)

We use the notation in the Introduction, along with U_i for the ith row of U and V_j for the jth row of V. Since we wish U_i V_j' to estimate R_ij, the most natural Bayesian model would begin with the following conditional distribution on each R_ij:
R_ij|U_i,V_j ~ N(U_i V_j',sigma^2)
Also for simplicity in calculation, we assume that R_ij, conditioned on the values of U and V, are independent random variables. Hence:

Equation (1) , but use (ij) for the bounds of the product instead of using the indicators I_ij.

where (ij) ranges over all user/movie indices in the training set.
The paper does not mention that although R_ij is in fact a discrete, integer-valued RV, it is modelled by a continuous distribution. This model is, however, justified as there is no requirement that the prediction must also be integer-valued. It is in fact beneficial to model R_ij as a continuous RV, since then non-integer part of the prediction would be helpful in distinguishing the top recommendations from the good ones.

Moreover we set U and V to be random variables, on which we put Gaussian priors with zero mean and spherical covariance(a multiple of the identity matrix):

Equation (2)

These priors can be interpreted as a natural regularisation induced by our Bayesian model, which can help reduce overfitting. We will see below how the values of sigma can be interpreted as the degree of regularisation. Here one could also raise the issue whether it is sensible to use a spherical covariance as opposed to, say, a diagonal covariance. The paper confirms experimentally that emprically this generalisation does not give much of an improvement, hence the paper adheres to a spherical variance for the sake of simplicity. 

By Bayes' Theorem the log posterior of U and V can be calculated as:

Equation (3)

where C is some constant independent of the parameters. Maximising the log-posterior over U and V is then equivalent to minimising the sum of squared errors with quadratic regularisation terms:

Equation (4)

where lambdaU= , .... . . Although unmentioned in the paper, this form of quadratic regularisation, as in ridge regression, is intuitively the type of regularisation we would want to avoid overfitting; with careful optimisation, U and V with large entries may have low error on observed entries of R. Then, however, predictions for unobserved entries can become extreme, and due to the extreme sparsity of R, this will become a major issue when trying to predict many ratings, as is the case for the Netflix Prize. So it is sensible to have U and V small by penalising their L2 norms. This demonstrates that the use of a Gaussian prior on U and V, and using a maximum a posteriori (MAP) estimate is advantageous for three reasons: First, it automatically provides sensible and intuitive regularisation. Secondly it adds interpretive value to the parameter sigma (degree of regularisation). And thirdly, the parameters whose values we need to fix is reduced from three (sigmas) to two (lambdas), making easier the tuning parameter selection and hence effective regularisation.
Now the objective in (4) is minimised wrt U and V by gradient descent, hence U,V converge to a stationary point. 

Equation on top of page 6, but use epsilon instead of lambda

where the epsilon is the learning rate and p is the momentum term, which is used to avoid slow convergence due to heavy zig-zagging behaviour. Since del(E) is continuous, we may guarantee convergence to a local minimum by adjusting epsilon at each step of the iteration such that the Wolfe conditions are satisfied. However this is computationally demanding due to the large number of variables (N rows in U), so we use a constant learning rate. 

-Algorithm pseudocode.

-mention modification such as applying transformation to UV' and how this links to Gaussian Process approach in section 6.

-mention adaptive priors method.

-how the parameters were chosen for fixed prior PMF.

-brief statement of constrained PMF model.

-include figure 1 in paper - graphical model






